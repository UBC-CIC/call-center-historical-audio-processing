AWSTemplateFormatVersion: '2010-09-09'
Description: >
  "AI Powered Speach Analytics for Amazon Connect:
  - Create the basic foundation for streaming customer audio from Amazon Connect by deploying:
  - S3 Bucket for audio files, and the sample contact flow
  - Dynamo DB tables: transcriptSegments, transcriptSegmentsToCustomer, and contactDetails
  - A Lambda triggered on inbound contacts to store the initial contact details
  - A Lambda to trigger and pass the stream details to the Java Lambda
  - A Java Lambda to consume KVS and stream it to Amazon Transcribe, store the segments in DDB and upload the raw audio to S3
  - A Node.js Lambda triggered by S3 once WAV file is uploaded to store the concatenated transcript segments in the contact details table along with the S3 location of the audio file
  - A Node.js Lambda triggered by CloudFormation to create a sample Amazon Connect contact flow, pre-populated with the Lambda ARNs and placed in the S3 bucket for you to import in to your Amazon Connect instance.
Mappings:
  FunctionMap:
    Configuration:
      SolutionID: "SOXXXX"
  Send:
    AnonymousUsage:
      Data: "Yes"
Metadata:
  'AWS::CloudFormation::Interface':
    ParameterGroups:
      - Label:
          default: Existing configuration
          Parameters:
            - existingS3BucketName
            - existingS3Path
      - Label:
          default: Amazon S3 Configuration
        Parameters:
          - s3BucketName
      - Label:
          default: Amazon DynamoDB Configuration
        Parameters:
          - transcriptSegmentsTable
          - transcriptSegmentsToCustomerTable
          - contactDetailsTable
    ParameterLabels:
      s3BucketName:
        default: Bucket Name
      transcriptSegmentsTable:
        default: Transcript Table Name for audio from the customer
      transcriptSegmentsToCustomerTable:
        default: Transcript Table Name for audio to the customer
      contactDetailsTable:
        default: Contacts Table Name
      existingS3Path:
        default: Existing S3 Bucket Name
      existingS3BucketName:
        default: Existing Path in the existing S3 Bucket
Parameters:
  s3BucketName:
    Type: String
    Default: "ecomm911-new-bucket-name"
    Description: >
      Enter the (globally unique) name you would like to use for the Amazon S3 bucket where we will store the audio files, and the sample contact flow.
      This template will fail to deploy if the bucket name you chose is currently in use.
    AllowedPattern: '(?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)'
  esDomainName:
    Type: String
    Default: ecomm-sop-search
    Description: Name for the Amazon ES domain that this template will create. Domain names must start with a lowercase letter and must be between 3 and 28 characters. Valid characters are a-z (lowercase only), 0-9.
  transcriptSegmentsTable:
    Type: String
    Default:  contactTranscriptSegments
    Description:  The name of the DynamoDB Table where segments (utterances) from the customer for the caller transcript will be saved (Ensure you do not have a table with this name already).
  transcriptSegmentsToCustomerTable:
    Type: String
    Default:  contactTranscriptSegmentsToCustomer
    Description:  The name of the DynamoDB Table where segments (utterances) to the customer for the caller transcript will be saved (Ensure you do not have a table with this name already).
  contactDetailsTable:
    Type: String
    Default:  contactDetails
    Description:  The name of the DynamoDB Table where contact details will be written (Ensure you do not have a table with this name already).
  existingS3BucketName:
    Type: String
    Default: existingS3Bucket
    Description: The name of the S3 bucket that contains the zipped lambda files
  existingS3Path:
    Type: String
    Default: existingS3Path/
    Description: The path to the zipped lambda files in the existingS3BucketName
Outputs:
  transcriptSegmentsDDBTable:
    Description:  The ARN of the DynamoDB table created to store segments of call transcripts (customer audio)
    Value: !GetAtt transcriptSegmentsDDBTable.Arn
  contactsDDBTable:
    Description:  The ARN of the DynamoDB table created to store contact details used in this solution
    Value: !GetAtt contactDetailsDDBTable.Arn
  initContactDetails:
    Description:  >
      AWS Lambda Function that will be triggered when the call starts so that we have the initial contact details which can later add to when we have the transcript, and audio file location.
    Value: !Ref initContactDetails
  transcriptionTrigger:
    Description:  >
      AWS Lambda Function to start (asynchronous) streaming transcription; it is expected to be called by the
      Amazon Connect Contact Flow.
    Value: !Ref kvsConsumerTrigger
  transcriptionTriggerARN:
    Description:  ARN for the TranscriptionTriggerFunction
    Value: !GetAtt kvsConsumerTrigger.Arn
  CallTranscription:
    Description:  AWS Lambda Function to get audio from Kinesis Video Streams and use Amazon Transcribe to get text for the caller audio.  Should be invoked by TranscriptionTrigger and write results to the transcriptSegments table.
    Value: !Ref kvsTranscriber
  createS3BucketOP:
    Description: Bucket contains all the call recordings and sample contactflow
    Value: !GetAtt [createS3Bucket, WebsiteURL]
  createS3BucketSSLOP:
    Description:  Bucket contains all the call recordings and sample contactflow
    Value: !Join ['', ['https://', !GetAtt [createS3Bucket, DomainName]]]

Resources:
  allowConnectToKvsConsumerTriggerLambda:
    Type: 'AWS::Lambda::Permission'
    Properties:
      FunctionName: !Ref kvsConsumerTrigger
      Action: 'lambda:InvokeFunction'
      Principal: connect.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'

  allowConnectToInitContactDetailsLambda:
    Type: 'AWS::Lambda::Permission'
    Properties:
      FunctionName: !Ref initContactDetails
      Action: 'lambda:InvokeFunction'
      Principal: connect.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'

  createS3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref s3BucketName
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: True
        BlockPublicPolicy: True
        IgnorePublicAcls: True
        RestrictPublicBuckets: True
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      CorsConfiguration:
        CorsRules:
          -   AllowedOrigins:
                - '*'
              AllowedHeaders:
                - '*'
              AllowedMethods:
                - PUT
                - HEAD
              MaxAge: '3000'

  transcriptSegmentsDDBTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName:  !Ref transcriptSegmentsTable
      AttributeDefinitions:
        -
          AttributeName: "ContactId"
          AttributeType: "S"
      KeySchema:
        -
          AttributeName: "ContactId"
          KeyType: "HASH"
      # assuming 5 concurrent calls
      ProvisionedThroughput:
        ReadCapacityUnits:
          5
        WriteCapacityUnits:
          5
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: True
      SSESpecification:
        SSEEnabled: True
      TimeToLiveSpecification:
        AttributeName:  "ExpiresOn"
        Enabled:  True
      StreamSpecification:
        StreamViewType: NEW_IMAGE

  transcriptSegmentsToCustomerDDBTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName:  !Ref transcriptSegmentsToCustomerTable
      AttributeDefinitions:
        -
          AttributeName: "ContactId"
          AttributeType: "S"
      KeySchema:
        -
          AttributeName: "ContactId"
          KeyType: "HASH"
      # assuming 5 concurrent calls
      ProvisionedThroughput:
        ReadCapacityUnits:
          5
        WriteCapacityUnits:
          5
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: True
      SSESpecification:
        SSEEnabled: True
      TimeToLiveSpecification:
        AttributeName:  "ExpiresOn"
        Enabled:  True
      StreamSpecification:
        StreamViewType: "NEW_IMAGE"

  contactDetailsDDBTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName:  !Ref contactDetailsTable
      AttributeDefinitions:
        -
          AttributeName: "contactId"
          AttributeType: "S"
      KeySchema:
        -
          AttributeName: "contactId"
          KeyType: "HASH"
      # assuming 5 concurrent calls
      ProvisionedThroughput:
        ReadCapacityUnits:
          5
        WriteCapacityUnits:
          5
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: True
      SSESpecification:
        SSEEnabled: True

  KvsTranscribeRole:
    Type: "AWS::IAM::Role"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: F3
            reason: transcribe:* do not support resource-level permissions and kinesisvideo streams are dynamically created and therefore cannot be specificed directly
          - id: W11
            reason: transcribe:* do not support resource-level permissions and kinesisvideo streams are dynamically created and therefore cannot be specificed directly
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: kvs-streaming-transcribe-policy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
              -
                Effect: "Allow"
                Action:
                  - "dynamodb:Query"
                  - "dynamodb:Scan"
                  - "dynamodb:GetItem"
                  - "dynamodb:PutItem"
                  - "dynamodb:UpdateItem"
                  - "dynamodb:GetRecords"
                  - "dynamodb:GetShardIterator"
                  - "dynamodb:DescribeStream"
                  - "dynamodb:ListStreams"
                Resource:
                  - !Sub ${transcriptSegmentsDDBTable.Arn}
                  - !Sub ${transcriptSegmentsToCustomerDDBTable.Arn}
              -
                Effect: "Allow"
                Action:
                  - "s3:PutObject"
                  - "s3:GetObject"
                  - "s3:PutObjectAcl"
                Resource:
                  - !Sub ${createS3Bucket.Arn}/*
              -
                Effect: "Allow"
                Action:
                  - "transcribe:DeleteTranscriptionJob"
                  - "transcribe:GetTranscriptionJob"
                  - "transcribe:GetVocabulary"
                  - "transcribe:ListTranscriptionJobs"
                  - "transcribe:ListVocabularies"
                  - "transcribe:StartStreamTranscription"
                  - "transcribe:StartTranscriptionJob"
                Resource: "*"
              -
                Effect: "Allow"
                Action:
                  - "kinesisvideo:Describe*"
                  - "kinesisvideo:Get*"
                  - "kinesisvideo:List*"
                Resource: "*"

  KvsTriggerRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: kvs-streaming-trigger-policy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
              -
                Effect: "Allow"
                Action:
                  - "lambda:InvokeFunction"
                  - "lambda:InvokeAsync"
                Resource:
                  - !GetAtt kvsTranscriber.Arn

  ContactFlowCreatorRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: contact-flow-creator-policy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
              -
                Effect: "Allow"
                Action:
                  - "s3:PutObject"
                Resource:
                  - !Sub ${createS3Bucket.Arn}/*

  ConnectUserStsRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              AWS:
                !Join
                - ''
                - - 'arn:'
                  - !Ref 'AWS::Partition'
                  - ':iam::'
                  - !Ref 'AWS::AccountId'
                  - ':'
                  - 'root'
            Action:
              - "sts:AssumeRole"
      Path: "/"

  ConnectUserStsPolicy:
    Type: 'AWS::IAM::Policy'
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W12
            reason: comprehend, translate, and connect do not support resource-level permissions
    Properties:
      PolicyName: !Sub ${AWS::StackName}-UserStsPolicy
      Roles:
        - !Ref ConnectUserStsRole
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Action:
              - "comprehend:ListEntityRecognizers"
              - "comprehend:DetectSentiment"
              - "comprehend:DetectEntities"
              - "comprehend:ListDocumentClassifiers"
              - "comprehend:DetectSyntax"
              - "comprehend:DetectKeyPhrases"
            Resource: "*"
          -
            Effect: "Allow"
            Action:
              - "translate:TranslateText"
            Resource: "*"
          -
            Effect: "Allow"
            Action:
              - "s3:PutObject"
            Resource:
              - !Sub ${createS3Bucket.Arn}/*
          -
            Effect: "Allow"
            Action:
              - "connect:UpdateContactAttributes"
            Resource: "*"

  STSTokenLambdaIAMRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: connect-aipsas-ststoken
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
              -
                Effect: "Allow"
                Action:
                  - "dynamodb:UpdateItem"
                Resource:
                  - !Sub ${contactDetailsDDBTable.Arn}
              - Effect: "Allow"
                Action:
                  - 'sts:AssumeRole'
                Resource:
                  - !GetAtt ConnectUserStsRole.Arn
                  
  TranscribeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: dynamodb-stream-transcribe-policy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "lambda:InvokeFunction"
                Resource: "*"
              -
                Effect: "Allow"
                Action:
                  - "dynamodb:DescribeStream"
                  - "dynamodb:GetRecords"
                  - "dynamodb:GetShardIterator"
                  - "dynamodb:ListStreams"
                  - "dynamodb:Query"
                  - "dynamodb:Scan"
                  - "dynamodb:GetItem"
                  - "dynamodb:PutItem"
                  - "dynamodb:UpdateItem"
                Resource:
                  - !GetAtt transcriptSegmentsDDBTable.StreamArn
                  - !GetAtt transcriptSegmentsToCustomerDDBTable.StreamArn
              -
                Effect: "Allow"
                Action:
                  - "comprehend:DetectEntities"
                  - "comprehend:DetectKeyPhrases"
                Resource: "*"
              -
                Effect: "Allow"
                Action:
                  - es:*
                Resource: "*"

  kvsTranscriber:
    Type: "AWS::Lambda::Function"
    Properties:
      Description:  >
        Process audio from Kinesis Video Stream and use Amazon Transcribe to get text
        for the caller audio. Will be invoked by the kvsConsumerTrigger Lambda, writes results to the
        transcript DynamoDB tables, and uploads the audio file to S3.

      Handler: "com.amazonaws.kvstranscribestreaming.KVSTranscribeStreamingLambda::handleRequest"
      Role: !GetAtt KvsTranscribeRole.Arn
      Runtime: java8
      MemorySize: 512
      # maximum timeout is 15 minutes today
      Timeout: 900
      Environment:
        Variables:
          # JAVA_TOOL_OPTIONS: "-Djavax.net.ssl.trustStore=lib/InternalAndExternalTrustStore.jks -Djavax.net.ssl.trustStorePassword=amazon"
          APP_REGION: !Ref "AWS::Region"
          TRANSCRIBE_REGION: !Ref "AWS::Region"
          RECORDINGS_BUCKET_NAME: !Ref s3BucketName
          TABLE_CALLER_TRANSCRIPT: !Ref transcriptSegmentsTable
          TABLE_CALLER_TRANSCRIPT_TO_CUSTOMER: !Ref transcriptSegmentsToCustomerTable
          RECORDINGS_PUBLIC_READ_ACL: "FALSE"
          CONSOLE_LOG_TRANSCRIPT_FLAG: "TRUE"
          LOGGING_LEVEL: "FINE"
          SAVE_PARTIAL_TRANSCRIPTS: "TRUE"
          START_SELECTOR_TYPE: "NOW"
          SEND_ANONYMOUS_DATA: !FindInMap [ "Send", "AnonymousUsage", "Data"]

      Code:
        S3Bucket: !Ref existingS3BucketName
        S3Key: !Join ["", [!Ref existingS3Path, 'ecomm-911-virtual-assistant.zip']]

  kvsConsumerTrigger:
    Type: "AWS::Lambda::Function"
    Properties:
      Description:  >
        AWS Lambda Function to start (asynchronous) streaming transcription; it is expected to be called by the
        Amazon Connect Contact Flow.
      Handler: "kvs_trigger.handler"
      Role: !GetAtt KvsTriggerRole.Arn
      Runtime: "nodejs12.x"
      MemorySize: 128
      Timeout: 30
      Environment:
        Variables:
          transcriptionFunction: !Ref kvsTranscriber
      Code:
        S3Bucket: !Ref existingS3BucketName
        S3Key: !Join ["", [!Ref existingS3Path, 'kvs_trigger.zip']]

  initContactDetails:
    Type: "AWS::Lambda::Function"
    Properties:
      Description:  >
        AWS Lambda Function that will be triggered when the call starts so that we have the initial contact details which can later add to when we have the transcript, and audio file location.
      Handler: "contact_init.handler"
      Role: !GetAtt STSTokenLambdaIAMRole.Arn
      Runtime: "nodejs12.x"
      MemorySize: 128
      Timeout: 30
      Environment:
        Variables:
          table_name: !Ref contactDetailsTable
          assume_role: !GetAtt ConnectUserStsRole.Arn
      Code:
        S3Bucket: !Ref existingS3BucketName
        S3Key: !Join ["", [!Ref existingS3Path, 'contact_init.zip']]

  contactFlowCreator:
    Type: "AWS::Lambda::Function"
    Properties:
      Description:  >
        AWS Lambda Function that will create the initial sample contact flow and upload it to the S3 bucket
      Handler: "create_contact_flow.handler"
      Role: !GetAtt ContactFlowCreatorRole.Arn
      Runtime: "nodejs12.x"
      MemorySize: 256
      Timeout: 120
      Code:
        S3Bucket: !Ref existingS3BucketName
        S3Key: !Join ["", [!Ref existingS3Path, 'create_contact_flow.zip']]

  comprehendTranscribedAudioText:
    Type: "AWS::Lambda::Function"
    Properties:
      Description:  >
        AWS Lambda Function that runs the transcribed text through AWS Comprehend
      Handler: "preprocess.handler"
      Role: !GetAtt TranscribeRole.Arn
      Runtime: "python3.8"
      MemorySize: 256
      Timeout: 120
      Environment:
        Variables:
          bucket_name: !Ref s3BucketName
          esDomain: !GetAtt ESDomain.DomainEndpoint
      Code:
        S3Bucket: !Ref existingS3BucketName
        S3Key: !Join ["", [!Ref existingS3Path, 'preprocess.zip']]

  comprehendTranscribedAudioTextEventMapping:
    Type: "AWS::Lambda::EventSourceMapping"
    Properties:
      EventSourceArn: !GetAtt transcriptSegmentsDDBTable.StreamArn
      FunctionName: !GetAtt comprehendTranscribedAudioText.Arn
      StartingPosition: "TRIM_HORIZON"
      Enabled: True

  comprehendTranscribedAudioTextToCustomerEventMapping:
    Type: "AWS::Lambda::EventSourceMapping"
    Properties:
      EventSourceArn: !GetAtt transcriptSegmentsToCustomerDDBTable.StreamArn
      FunctionName: !GetAtt comprehendTranscribedAudioText.Arn
      StartingPosition: "TRIM_HORIZON"
      Enabled: True

  invokeContactFlowCreator:
    Type: Custom::CreateKVSContactFlow
    Properties:
      ServiceToken:
        !GetAtt contactFlowCreator.Arn
      bucketName:
        !Ref createS3Bucket
      contactInitFunction:
        !GetAtt initContactDetails.Arn
      kvsTriggerFunction:
        !GetAtt kvsConsumerTrigger.Arn

  ESDomain:
    Type: AWS::Elasticsearch::Domain
    Properties:
      DomainName:
        Ref: esDomainName
      ElasticsearchVersion: '6.3'
      ElasticsearchClusterConfig:
        InstanceCount: '1'
        InstanceType: t2.small.elasticsearch
      EBSOptions:
        EBSEnabled: true
        Iops: 0
        VolumeSize: 10
        VolumeType: gp2
      SnapshotOptions:
        AutomatedSnapshotStartHour: '0'
  
  createESKeyPhraseIndex:
    Type: AWS::Lambda::Function
    Properties:
      Description:  >
        "Triggered by S3 review upload to the repo bucket and start the key phrase analysis via Amazon Comprehend"
      Handler: comprehend.handler
      Role: !GetAtt ESTriggerRole.Arn
      Runtime: python3.6
      MemorySize: 128
      Timeout: 300
      Environment:
        Variables:
          bucket: !Ref s3BucketName
          esDomain: !GetAtt ESDomain.DomainEndpoint
      Code:
        S3Bucket: !Ref existingS3BucketName
        S3Key: !Join ["", [!Ref existingS3Path, 'ES_comprehend.zip']]
  
  ESTriggerRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: "/"
      Policies:
        -
          PolicyName: S3-lambda-trigger-policy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Sid: "comprehend"
                Effect: Allow
                Action:
                  - comprehend:*
                Resource: "*"
              -
                Sid: "s3"
                Effect: Allow
                Action:
                  - s3:*
                Resource: !Sub "arn:aws:s3:::${s3BucketName}/*"
              -
                Sid: "es"
                Effect: Allow
                Action:
                  - es:*
                Resource: "*"

  TestS3BucketEventPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:invokeFunction
      SourceAccount: !Ref 'AWS::AccountId'
      FunctionName: !Ref 'createESKeyPhraseIndex'
      SourceArn: !GetAtt createS3Bucket.Arn
      Principal: s3.amazonaws.com

  ApplyNotificationFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: S3BucketNotificationPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Sid: AllowBucketNotification
                Effect: Allow
                Action: s3:PutBucketNotification
                Resource:
                  - !Sub '${createS3Bucket.Arn}'
                  - !Sub '${createS3Bucket.Arn}/*'
                  
                  
  ApplyBucketNotificationFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: function that will apply the notification event onto the bucket
      Handler: index.handler
      Runtime: python2.7
      Role: !GetAtt 'ApplyNotificationFunctionRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import boto3
          import logging
          import json
          import cfnresponse

          s3Client = boto3.client('s3')
          logger = logging.getLogger()
          logger.setLevel(logging.DEBUG)

          def addBucketNotification(bucketName, notificationId, functionArn):
            notificationResponse = s3Client.put_bucket_notification_configuration(
              Bucket=bucketName,
              NotificationConfiguration={
                'LambdaFunctionConfigurations': [
                  {
                    'Id': notificationId,
                    'LambdaFunctionArn': functionArn,
                    'Events': [
                      's3:ObjectCreated:*'
                    ],
                    'Filter': {
                      'Key': {
                        'FilterRules': [
                          {
                            'Name': 'suffix',
                            'Value': 'pdf'
                          }
                        ]
                      }
                    }
                  },
                ]
              }
            )
            return notificationResponse

          def create(properties, physical_id):
            bucketName = properties['S3Bucket']
            notificationId = properties['NotificationId']
            functionArn = properties['FunctionARN']
            response = addBucketNotification(bucketName, notificationId, functionArn)
            logger.info('AddBucketNotification response: %s' % json.dumps(response))
            return cfnresponse.SUCCESS, physical_id

          def update(properties, physical_id):
            return cfnresponse.SUCCESS, None

          def delete(properties, physical_id):
            return cfnresponse.SUCCESS, None

          def handler(event, context):
            logger.info('Received event: %s' % json.dumps(event))

            status = cfnresponse.FAILED
            new_physical_id = None

            try:
              properties = event.get('ResourceProperties')
              physical_id = event.get('PhysicalResourceId')

              status, new_physical_id = {
                'Create': create,
                'Update': update,
                'Delete': delete
              }.get(event['RequestType'], lambda x, y: (cfnresponse.FAILED, None))(properties, physical_id)
            except Exception as e:
              logger.error('Exception: %s' % e)
              status = cfnresponse.FAILED
            finally:
              cfnresponse.send(event, context, status, {}, new_physical_id)

  ApplyNotification:
    Type: Custom::ApplyNotification
    Properties:
      ServiceToken: !GetAtt ApplyBucketNotificationFunction.Arn
      S3Bucket: !Ref createS3Bucket
      FunctionARN: !GetAtt createESKeyPhraseIndex.Arn
      NotificationId: S3ObjectCreatedEvent
